{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPO2SpQKXhbv6lb7OoP36S6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keduog/LLM/blob/main/spiro_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5Xhjw5HdMEP"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
        "model.eval()\n",
        "\n",
        "def extract_all_layer_head_embeddings(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "        hidden_states = outputs.hidden_states[1:]  # skip embedding layer (len=12 for BERT-base)\n",
        "\n",
        "    all_heads = []\n",
        "    for layer in hidden_states:  # loop over each of the 12 layers\n",
        "        layer = layer.squeeze(0)  # (seq_len, 768)\n",
        "        heads = layer.view(layer.size(0), 12, 64)  # simulate splitting into 12 heads\n",
        "        head_embeddings = heads.mean(dim=0)  # (12 heads, 64)\n",
        "        all_heads.append(head_embeddings)\n",
        "\n",
        "    # Stack into shape (12 layers × 12 heads, 64 dim)\n",
        "    all_heads_tensor = torch.cat(all_heads, dim=0)  # (144, 64)\n",
        "    return all_heads_tensor\n",
        "\n",
        "def draw_spirograph(R, r, d, x_offset=0, y_offset=0, steps=1000):\n",
        "    t = np.linspace(0, 2 * np.pi * 5, steps)\n",
        "    x = (R - r) * np.cos(t) + d * np.cos((R - r) / r * t) + x_offset\n",
        "    y = (R - r) * np.sin(t) - d * np.sin((R - r) / r * t) + y_offset\n",
        "    return x, y\n",
        "\n",
        "def plot_all_heads_spirograph(sentence):\n",
        "    all_heads = extract_all_layer_head_embeddings(sentence)\n",
        "\n",
        "    # Project all 144 (12 layers × 12 heads) head embeddings to 2D using PCA\n",
        "    pca = PCA(n_components=2)\n",
        "    reduced = pca.fit_transform(all_heads.numpy())\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for idx, (x_val, y_val) in enumerate(reduced):\n",
        "        layer = idx // 12\n",
        "        head = idx % 12\n",
        "        R = 40 + x_val * 10\n",
        "        r = 10 + abs(y_val) * 5\n",
        "        d = 20\n",
        "        x, y = draw_spirograph(R, r, d)\n",
        "        plt.plot(x, y, label=f\"L{layer+1}H{head}\", alpha=0.7)\n",
        "\n",
        "    plt.title(f\"Spirograph of All Heads Across All Layers\\nSentence: \\\"{sentence}\\\"\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.legend(loc=\"upper right\", bbox_to_anchor=(1.25, 1.0))\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_all_heads_spirograph(\"The dog sat on the mat\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
        "model.eval()\n",
        "\n",
        "def extract_all_layer_head_embeddings(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "        hidden_states = outputs.hidden_states[1:]  # skip embedding layer\n",
        "\n",
        "    all_heads = []\n",
        "    for layer in hidden_states:  # 12 layers\n",
        "        layer = layer.squeeze(0)  # (seq_len, 768)\n",
        "        heads = layer.view(layer.size(0), 12, 64)  # (seq_len, 12, 64)\n",
        "        head_embeddings = heads.mean(dim=0)  # (12, 64)\n",
        "        all_heads.append(head_embeddings)\n",
        "\n",
        "    return torch.cat(all_heads, dim=0)  # shape: (12 layers * 12 heads = 144, 64)\n",
        "\n",
        "def draw_spirograph(R, r, d, x_offset=0, y_offset=0, steps=1000):\n",
        "    t = np.linspace(0, 2 * np.pi * 5, steps)\n",
        "    x = (R - r) * np.cos(t) + d * np.cos((R - r) / r * t) + x_offset\n",
        "    y = (R - r) * np.sin(t) - d * np.sin((R - r) / r * t) + y_offset\n",
        "    return x, y\n",
        "\n",
        "def plot_all_heads_spirograph(sentence):\n",
        "    all_heads = extract_all_layer_head_embeddings(sentence)\n",
        "    pca = PCA(n_components=2)\n",
        "    reduced = pca.fit_transform(all_heads.numpy())  # (144, 2)\n",
        "\n",
        "    # Prepare colors for each layer\n",
        "    color_map = cm.get_cmap(\"tab20\", 12)  # 12 distinct colors for 12 layers\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for idx, (x_val, y_val) in enumerate(reduced):\n",
        "        layer = idx // 12\n",
        "        head = idx % 12\n",
        "        R = 40 + x_val * 10\n",
        "        r = 10 + abs(y_val) * 5\n",
        "        d = 20\n",
        "        x, y = draw_spirograph(R, r, d)\n",
        "        plt.plot(x, y, label=f\"L{layer+1}H{head}\", color=color_map(layer), alpha=0.8)\n",
        "\n",
        "    plt.title(f\"Spirograph of All Heads Across All Layers\\nSentence: \\\"{sentence}\\\"\")\n",
        "    plt.axis(\"off\")\n",
        "    # Show legend grouped by layer only once per layer\n",
        "    custom_lines = [plt.Line2D([0], [0], color=color_map(i), lw=2) for i in range(12)]\n",
        "    plt.legend(custom_lines, [f\"Layer {i+1}\" for i in range(12)], loc=\"upper right\", bbox_to_anchor=(1.25, 1.0))\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_all_heads_spirograph(\"The dog sat on the mat\")\n"
      ],
      "metadata": {
        "id": "AX9p23PNf-6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
        "model.eval()\n",
        "\n",
        "def extract_all_layer_head_embeddings(sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "        hidden_states = outputs.hidden_states[1:]  # skip embedding layer\n",
        "\n",
        "    all_heads = []\n",
        "    for layer in hidden_states:  # 12 layers\n",
        "        layer = layer.squeeze(0)  # (seq_len, 768)\n",
        "        heads = layer.view(layer.size(0), 12, 64)  # (seq_len, 12, 64)\n",
        "        head_embeddings = heads.mean(dim=0)  # (12, 64)\n",
        "        all_heads.append(head_embeddings)\n",
        "\n",
        "    return torch.cat(all_heads, dim=0)  # (144, 64)\n",
        "\n",
        "def draw_spirograph(R, r, d, x_offset=0, y_offset=0, steps=1000):\n",
        "    t = np.linspace(0, 2 * np.pi * 5, steps)\n",
        "    x = (R - r) * np.cos(t) + d * np.cos((R - r) / r * t) + x_offset\n",
        "    y = (R - r) * np.sin(t) - d * np.sin((R - r) / r * t) + y_offset\n",
        "    return x, y\n",
        "\n",
        "def get_distinct_colors(n):\n",
        "    base_colors = list(mcolors.TABLEAU_COLORS.values())  # 10 very distinct\n",
        "    extra_colors = [\n",
        "        \"#e41a1c\", \"#377eb8\", \"#4daf4a\", \"#984ea3\", \"#ff7f00\",\n",
        "        \"#ffff33\", \"#a65628\", \"#f781bf\", \"#999999\"\n",
        "    ]\n",
        "    all_colors = base_colors + extra_colors\n",
        "    return all_colors[:n]\n",
        "\n",
        "def plot_all_heads_spirograph(sentence):\n",
        "    all_heads = extract_all_layer_head_embeddings(sentence)\n",
        "    pca = PCA(n_components=2)\n",
        "    reduced = pca.fit_transform(all_heads.numpy())  # (144, 2)\n",
        "\n",
        "    # Get 12 distinct colors\n",
        "    colors = get_distinct_colors(12)\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for idx, (x_val, y_val) in enumerate(reduced):\n",
        "        layer = idx // 12\n",
        "        head = idx % 12\n",
        "        R = 40 + x_val * 10\n",
        "        r = 10 + abs(y_val) * 5\n",
        "        d = 20\n",
        "        x, y = draw_spirograph(R, r, d)\n",
        "        plt.plot(x, y, label=f\"L{layer+1}H{head}\", color=colors[layer], alpha=0.85)\n",
        "\n",
        "    plt.title(f\"Spirograph of All Heads Across All Layers\\nSentence: \\\"{sentence}\\\"\")\n",
        "    plt.axis(\"off\")\n",
        "    custom_lines = [plt.Line2D([0], [0], color=colors[i], lw=3) for i in range(12)]\n",
        "    plt.legend(custom_lines, [f\"Layer {i+1}\" for i in range(12)], loc=\"upper right\", bbox_to_anchor=(1.25, 1.0))\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_all_heads_spirograph(\"he is asodfjsdlfkj, ehrereowekjwlekjwl\")\n"
      ],
      "metadata": {
        "id": "25-OFoIvgTPL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}