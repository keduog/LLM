{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNQsoAKe0gOt/icbCMYJpk7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keduog/LLM/blob/main/exam_evaluation_RAG_bloom_taxonomy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYuynubuK2yL"
      },
      "outputs": [],
      "source": [
        "# --- Biology Exam Evaluation with RAG + Falcon-7B-Instruct (Fully Public) ---\n",
        "\n",
        "# STEP 1: Install Required Libraries\n",
        "!pip install -q sentence-transformers faiss-cpu transformers accelerate bitsandbytes\n",
        "\n",
        "# STEP 2: Import Libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from google.colab import files\n",
        "\n",
        "# STEP 3: Upload CSV Files (grade9Q.csv, biologyg9.csv)\n",
        "uploaded = files.upload()\n",
        "\n",
        "# STEP 4: Load Data\n",
        "exam_df = pd.read_csv(\"grade9Q.csv\", encoding=\"utf-8\")\n",
        "textbook_df = pd.read_csv(\"biologyg9.csv\", encoding=\"ISO-8859-1\")  # Columns: Unit, Section, Text\n",
        "\n",
        "# STEP 5: Encode Textbook Content for RAG\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "text_chunks = textbook_df[\"Text\"].tolist()\n",
        "chunk_embeddings = embedder.encode(text_chunks, convert_to_tensor=True)\n",
        "\n",
        "# STEP 6: Match Questions to Textbook Sections\n",
        "matched_units = []\n",
        "matched_sections = []\n",
        "\n",
        "threshold = 0.9\n",
        "for question in exam_df[\"question_text\"]:\n",
        "    q_embed = embedder.encode(question, convert_to_tensor=True)\n",
        "    similarities = util.cos_sim(q_embed, chunk_embeddings)\n",
        "    best_idx = similarities.argmax().item()\n",
        "    best_score = similarities[0][best_idx].item()\n",
        "\n",
        "    if best_score >= threshold:\n",
        "        matched_units.append(textbook_df.iloc[best_idx][\"Unit\"])\n",
        "        matched_sections.append(textbook_df.iloc[best_idx][\"Section\"])\n",
        "    else:\n",
        "        matched_units.append(\"No Match\")\n",
        "        matched_sections.append(\"No Match\")\n",
        "\n",
        "exam_df[\"matched_unit\"] = matched_units\n",
        "exam_df[\"matched_section\"] = matched_sections\n",
        "\n",
        "# STEP 7: Pedagogical Check - All Questions Should Have 4 Options\n",
        "exam_df[\"option_count_valid\"] = exam_df.apply(\n",
        "    lambda row: all(pd.notnull(row[f\"option_{i}\"]) for i in range(1, 5)),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# STEP 8: Load Falcon-7B-Instruct Model (No API Key Required)\n",
        "model_id = \"tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "llama_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# STEP 9: Define Difficulty Classifier\n",
        "def classify_difficulty(question):\n",
        "    prompt = (\n",
        "        \"You are a biology teacher.\\n\"\n",
        "        \"Classify the following multiple-choice question into one of three categories: Easy, Medium, or Difficult.\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Only answer with one word: Easy, Medium, or Difficult.\"\n",
        "    )\n",
        "    try:\n",
        "        output = llama_pipeline(prompt, max_new_tokens=10, do_sample=False)[0][\"generated_text\"]\n",
        "        for word in [\"Easy\", \"Medium\", \"Difficult\"]:\n",
        "            if word in output:\n",
        "                return word\n",
        "        return \"Unclear\"\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        return \"Error\"\n",
        "\n",
        "# STEP 10: Classify Difficulty for All Questions\n",
        "exam_df[\"difficulty\"] = exam_df[\"question_text\"].apply(classify_difficulty)\n",
        "\n",
        "# STEP 11: Bloom's Taxonomy Classification Function\n",
        "def classify_blooms_taxonomy(question):\n",
        "    prompt = (\n",
        "        \"You are an expert in educational assessment.\\n\"\n",
        "        \"Classify the cognitive level of the following multiple-choice biology question based on Bloom's Revised Taxonomy.\\n\"\n",
        "        \"The levels are: Remember, Understand, Apply, Analyze, Evaluate, and Create.\\n\"\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Only respond with one word from the list above.\"\n",
        "    )\n",
        "    try:\n",
        "        output = llama_pipeline(prompt, max_new_tokens=10, do_sample=False)[0][\"generated_text\"]\n",
        "        for level in [\"Remember\", \"Understand\", \"Apply\", \"Analyze\", \"Evaluate\", \"Create\"]:\n",
        "            if level in output:\n",
        "                return level\n",
        "        return \"Unclear\"\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Bloom Classification Error: {e}\")\n",
        "        return \"Error\"\n",
        "\n",
        "# STEP 12: Classify Bloom's Taxonomy Level\n",
        "exam_df[\"bloom_level\"] = exam_df[\"question_text\"].apply(classify_blooms_taxonomy)\n",
        "\n",
        "# STEP 13: Print Summary\n",
        "print(\"\\n=== Coverage by Section ===\")\n",
        "print(exam_df[\"matched_section\"].value_counts())\n",
        "\n",
        "print(\"\\n=== Difficulty Level Distribution ===\")\n",
        "print(exam_df[\"difficulty\"].value_counts())\n",
        "\n",
        "print(\"\\n=== Bloom's Taxonomy Distribution ===\")\n",
        "print(exam_df[\"bloom_level\"].value_counts())\n",
        "\n",
        "print(\"\\n=== Pedagogical Violations (≠ 4 options) ===\")\n",
        "print(len(exam_df[~exam_df[\"option_count_valid\"]]))\n",
        "\n",
        "# STEP 14: Save and Download Results\n",
        "exam_df.to_csv(\"evaluated_exam_falcon.csv\", index=False)\n",
        "files.download(\"evaluated_exam_falcon.csv\")\n"
      ]
    }
  ]
}